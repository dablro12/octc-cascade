{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "project_root = os.path.abspath('/home/eiden/eiden/octc-cascade')\n",
    "sys.path.append(project_root)\n",
    "\n",
    "import torch \n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from models.segment import load_segment_model \n",
    "from models.inpaint import load_inpaint_model\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "from utils.__init__ import *\n",
    "from utils.dataset import Inference_Cascade_CustomDataset\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_img_dir = '/mnt/HDD/octc/seg_data/test_img'\n",
    "ts_mask_dir = '/mnt/HDD/octc/seg_data/test_mask'\n",
    "\n",
    "width, height = 512,512\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((width, height)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "test_dataset = Inference_Cascade_CustomDataset(\n",
    "    image_dir = ts_img_dir,\n",
    "    transform= test_transform,\n",
    "    seed = 627\n",
    ")\n",
    "\n",
    "ts_batch = 9\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = ts_batch, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, paths in test_loader:\n",
    "    # mask가 0이 아닌 부분에 대해 image를 mask로 대체\n",
    "    plt.imshow(images[0].permute(1,2,0), cmap = 'gray')\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cascade_models_load:\n",
    "    def __init__(self, seg_model_path, inpaint_model_path, device):\n",
    "        self.seg_model_name = seg_model_path.split('/')[-2]\n",
    "        self.inpaint_model_name = inpaint_model_path.split('/')[-2]\n",
    "        self.seg_model_path = seg_model_path\n",
    "        self.inpaint_model_path = inpaint_model_path\n",
    "        self.device = device\n",
    "        \n",
    "    def init_seg_model(self):\n",
    "        model_save_path = os.path.dirname(self.seg_model_path)\n",
    "        model_version = self.seg_model_path.split('/')[-1]\n",
    "        if self.seg_model_path.split('/')[-2].split('_')[0] == 'monai':\n",
    "            model_name = 'monai_swinunet'\n",
    "        else:\n",
    "            model_name = self.seg_model_path.split('/')[-2].split('_')[0]\n",
    "        print(f\" Model save path : {model_save_path}\")\n",
    "        print(f\" Model version : {model_version}\")\n",
    "        print(f\" Model name : {model_name}\")\n",
    "        \n",
    "        self.load_seg_model(model_save_path, model_version, model_name)\n",
    "        \n",
    "    def load_seg_model(self, model_save_path, model_version, model_name):\n",
    "        checkpoint = torch.load(os.path.join(model_save_path, model_version), map_location= self.device)['model_state_dict']\n",
    "        \n",
    "        seg_model_loader = load_segment_model.segmentation_models_loader(\n",
    "            model_name = model_name, width = width, height = height\n",
    "        )\n",
    "        self.seg_model = seg_model_loader.load_model().to(self.device)\n",
    "        self.seg_model.load_state_dict(checkpoint)\n",
    "    \n",
    "    def init_inpaint_model(self):\n",
    "        model_save_path = os.path.dirname(self.inpaint_model_path)\n",
    "        model_version = self.inpaint_model_path.split('/')[-1]\n",
    "        model_name = self.inpaint_model_path.split('/')[-2].split('_')[0]\n",
    "        print(f\" Model save path : {model_save_path}\")\n",
    "        print(f\" Model version : {model_version}\")\n",
    "        print(f\" Model name : {model_name}\")\n",
    "        \n",
    "        self.load_inpaint_model(model_save_path, model_version, model_name)\n",
    "\n",
    "    def load_inpaint_model(self, model_save_path, model_version, model_name):\n",
    "        checkpoint = torch.load(os.path.join(model_save_path, model_version), map_location= self.device)['netG_state_dict']\n",
    "        inpaint_model_loader = load_inpaint_model.inpainting_models_loader(\n",
    "            model_name = model_name, width = width, height = height\n",
    "        )\n",
    "        self.inpaint_model = inpaint_model_loader.load_model().to(self.device)\n",
    "        self.inpaint_model.load_state_dict(checkpoint)\n",
    "    def get_cascade_model_name(self):\n",
    "        cascade_model_name = self.seg_model_name + '@' + self.inpaint_model_name\n",
    "        return cascade_model_name \n",
    "        \n",
    "        \n",
    "    def load_models(self):\n",
    "        self.init_seg_model()\n",
    "        self.init_inpaint_model()\n",
    "        \n",
    "        return self.seg_model, self.inpaint_model\n",
    "        \n",
    "cascade_model_loader = cascade_models_load(\n",
    "    seg_model_path = '/mnt/HDD/oci-seg_models/monai_swinunet_v4_240530/model_400.pt',\n",
    "    inpaint_model_path = '/mnt/HDD/oci_models/aotgan/OCI-GAN_v3_240508/model_64.pt',\n",
    "    # inpaint_model_path = '/mnt/HDD/oci_models/models/VAE_v1_240510/model_27.pt',\n",
    "    \n",
    "    device = device\n",
    ")\n",
    "seg_model, inpaint_model = cascade_model_loader.load_models()\n",
    "cascade_model_name = cascade_model_loader.get_cascade_model_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cascade_result(image, segment_output, inpaint_mask, inpaint_input, pred_image, inpaint_output, save_path):\n",
    "    plt.figure(dpi = 256, figsize= (12,8))\n",
    "    plt.subplot(231)\n",
    "    plt.imshow(image, cmap= 'gray')\n",
    "    plt.title('Segment Input')\n",
    "    plt.subplot(232)\n",
    "    plt.imshow(segment_output, cmap= 'gray')\n",
    "    plt.title('Segment Result')\n",
    "    plt.subplot(233)\n",
    "    plt.imshow(inpaint_mask, cmap= 'gray')\n",
    "    plt.title('Inpainting Mask[PreProcess]')\n",
    "    plt.subplot(234)\n",
    "    plt.imshow(inpaint_input, cmap= 'gray')\n",
    "    plt.title('Inpainting Input')\n",
    "    plt.subplot(235)\n",
    "    plt.imshow(pred_image, cmap= 'gray')\n",
    "    plt.title('Inpainting Prediction')\n",
    "    plt.subplot(236)\n",
    "    plt.imshow(inpaint_output, cmap= 'gray')\n",
    "    plt.title('Inpainting Results[PostProcess]')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "\n",
    "def mask_preprocessing(images, seg_masks):\n",
    "    # seg_masks를 numpy로 변환후 opencv의 dilation 을 통해 확장한 후 다시 tensor로 변환 \n",
    "    seg_masks = seg_masks.cpu().detach().numpy().squeeze(1)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    dilated_seg_masks = []\n",
    "    for seg_mask in seg_masks:\n",
    "        dilated_seg_mask = cv2.dilate(seg_mask, kernel, iterations=4)\n",
    "        dilated_seg_mask = cv2.erode(dilated_seg_mask, kernel, iterations=2)\n",
    "        dilated_seg_masks.append(dilated_seg_mask)\n",
    "    \n",
    "    # dilated_seg_masks를 다시 numpy 배열로 변환\n",
    "    dilated_seg_masks = np.array(dilated_seg_masks)\n",
    "    # 다시 torch 텐서로 변환하고, 원래 디바이스로 이동\n",
    "    dilated_seg_masks = torch.tensor(dilated_seg_masks).unsqueeze(1).to(images.device)\n",
    "    \n",
    "    input_images = images.clone()\n",
    "    inpaint_masks = images.clone()\n",
    "    # -1~1로 범위로 정규화 되어있는 inpaint_mask를 0~1 범위로 다시 정규화\n",
    "    # inpaint_masks = (inpaint_masks + 1) / 2\n",
    "    # inpaint_masks = inpaint_masks / inpaint_masks.max()\n",
    "    \n",
    "    # 이미지와 마스크를 곱해서 배경을 제거\n",
    "    inpaint_masks = inpaint_masks * dilated_seg_masks\n",
    "\n",
    "    # input_images = (input_images + 1) / 2\n",
    "    # input_images = input_images / input_images.max()\n",
    "    input_images = input_images.repeat(1,3,1,1) # Inpaint Model 입력값에 맞춰주기 위함 \n",
    "    \n",
    "\n",
    "    return input_images, inpaint_masks\n",
    "\n",
    "def compute_composite_images(input_images, pred_images, inpaint_masks):\n",
    "    ## mask에서 0이 아닌 부분을 GT로 대체, 이때 마스크는 0~1사이의 값을 가짐 \n",
    "    comp_images = input_images.clone()\n",
    "    comp_images[inpaint_masks.repeat(1,3,1,1) != 0] = pred_images[inpaint_masks.repeat(1,3,1,1) != 0]\n",
    "    return comp_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "save_dir = os.path.join('/mnt/HDD/oci_cascade_models', cascade_model_name)\n",
    "os.makedirs(save_dir, exist_ok= True)\n",
    "with torch.no_grad():\n",
    "    seg_model.eval(), inpaint_model.eval()\n",
    "    for images, paths in test_loader:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # medical mark segment mask 생성 \n",
    "        seg_outputs = seg_model(images)\n",
    "        seg_outputs = torch.sigmoid(seg_outputs)\n",
    "        seg_outputs = (seg_outputs > threshold).float()\n",
    "        # inpainting model에 넣기 위한 mask 생성\n",
    "        inpaint_inputs, inpaint_masks = mask_preprocessing(images, seg_outputs)\n",
    "        \n",
    "        ################################################\n",
    "        # pred_images = inpaint_model(inpaint_inputs, seg_outputs) # ocigan\n",
    "        pred_images = inpaint_model(inpaint_inputs, inpaint_masks) # ocigan\n",
    "        # pred_images, _, _, _ = inpaint_model(images, inpaint_masks) # vae  \n",
    "        # pred_images= inpaint_model(images, inpaint_masks) #unet\n",
    "        ################################################\n",
    "        \n",
    "        # Post processing\n",
    "        comp_images = compute_composite_images(inpaint_inputs, pred_images, inpaint_masks)\n",
    "        # 결과 shpae \n",
    "        print('\\n', f\"Image shape : {images.shape}, Segment shape : {seg_outputs.shape})\")\n",
    "        print(f\"Inpaint Input shape : {inpaint_inputs.shape} Inpaint output shape : {comp_images.shape}\")\n",
    "        \n",
    "        # save_dir 과 paths를 이용하여 결과 저장\n",
    "        save_paths = [os.path.join(save_dir, os.path.basename(path)) for path in paths]\n",
    "        for i in range(len(test_loader)):\n",
    "            plot_cascade_result(\n",
    "                images[i,0].cpu().numpy(), seg_outputs[i,0].cpu().numpy(), inpaint_masks[i,0].cpu().numpy(),\n",
    "                inpaint_inputs[i,0].cpu().numpy(), pred_images[i,0].cpu().numpy(), comp_images[i,0].cpu().numpy(),\n",
    "                save_path = save_paths[i] \n",
    "            )\n",
    "        break \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eiden",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
